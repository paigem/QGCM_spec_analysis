{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from detrend_func import detrend_func\n",
    "from window_func import main as window_func\n",
    "\n",
    "import dask\n",
    "from distributed import Client, LocalCluster\n",
    "import dask.array as da\n",
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dask Distributed cluster with one processor and as many\n",
    "# threads as cores\n",
    "cluster = LocalCluster(n_workers=1)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define constants to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 5000. # meters\n",
    "dy = 5000. # meters\n",
    "dt = 1 # in days\n",
    "H = [350.0, 750.0, 2900.0]  # meters\n",
    "Htot = H[0] + H[1] + H[2]\n",
    "f0 = 9.37456*(10**(-5)) #1/s (Coriolis parameter)\n",
    "g = [.015, .0075]\n",
    "delta_ek = 2. # meters\n",
    "alpha_bc = 0.2 # nondimensional mixed boundary condition for OCEAN\n",
    "gamma = 0.5*alpha_bc + 1 # nondimensional number for ease of calculation\n",
    "mask = 0 # number of cells to mask at boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN ONCE ONLY\n",
    "\n",
    "#### ran on raijin with 32gb node. Takes about 70-80s per iteration\n",
    "\n",
    "\"\"\"\n",
    "indatadir = '/g/data1/v45/pm2987/Spunup'\n",
    "outdatadir = '/g/data1/v45/jm0634/paige/Spunup_T'\n",
    "\n",
    "for ncfile in ncfiles:\n",
    "    outncfile = ncfile.replace(indatadir, outdatadir)\n",
    "    outdir = os.path.dirname(outncfile)\n",
    "    \n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "        \n",
    "    if os.path.exists(outncfile):\n",
    "        continue\n",
    "        \n",
    "    ds = xr.open_dataset(ncfile)\\\n",
    "           .isel(time=slice(None,-1)) # remove last time value since it repeated at the\n",
    "                                      # start of each output file\n",
    "    ds = ds.transpose('zi', 'z', 'yp', 'xp', 'time')\n",
    "    \n",
    "    encoding = { 'p'    : {'chunksizes': [1, 100, 100, 365]},\n",
    "                 'q'    : {'chunksizes': [1, 100, 100, 365]},\n",
    "                 'h'    : {'chunksizes': [1, 100, 100, 365]},\n",
    "                 'taux' : {'chunksizes': [100, 100, 365]},\n",
    "                 'tauy' : {'chunksizes': [100, 100, 365]},              \n",
    "                 'e'    : {'chunksizes': [100, 100, 365]},\n",
    "               }\n",
    "    for v in encoding:\n",
    "        encoding[v].update({'complevel': 0, \n",
    "                            'contiguous': False,\n",
    "                            'dtype': np.dtype('float32'),\n",
    "                            'source': ncfile,\n",
    "                            'zlib': False})\n",
    "    \n",
    "    ds.to_netcdf(outncfile, engine='netcdf4', format='NETCDF4', encoding=encoding)\n",
    "    del ds\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/g/data1/v45/jm0634/paige/Spunup_T'\n",
    "\n",
    "# Select the desired files\n",
    "#ncfiles = sorted(glob(os.path.join(datadir, 'output*/ocpo.nc'))) # for all files\n",
    "ncfiles = sorted(glob(os.path.join(datadir, 'output013/ocpo.nc'))) # for one year\n",
    "#ncfiles = sorted(glob(os.path.join(datadir, 'output01*/ocpo.nc'))) # for seven years (1-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a DataArray of all output files (takes a few seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = {'xp': tile_size, 'yp': tile_size, \n",
    "          'time':365, 'z':1, 'zi':1}\n",
    "\n",
    "datasets = [xr.open_dataset(fn, \n",
    "                            chunks=chunks)\n",
    "            for fn in ncfiles]\n",
    "\n",
    "dsx = xr.concat(datasets, dim='time', coords='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KE\n",
    "\n",
    "$$\n",
    "-\\frac{H_1}{f_0^3 {H_{tot}}} \\mathrm{Re} \\left[  \\widehat{p_1}^* \n",
    "\\widehat{J(\\nabla_H^2 p_1,p_1)}\\right]\n",
    "- \\frac{H_2}{f_0^3 {H_{tot}}} \\mathrm{Re} \\left[  \\widehat{p_2}^* \n",
    "\\widehat{J(\\nabla_H^2 p_2, p_2)}\\right]\n",
    "-\\frac{H_3}{f_0^3 {H_{tot}}} \\mathrm{Re} \\left[  \\widehat{p_3}^* \n",
    "\\widehat{J(\\nabla_H^2 p_3, p_3)}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_KE(dsx, tile_index, z=0):\n",
    "    \n",
    "    # Select variable\n",
    "    p = dsx.p.isel(z=z)\n",
    "\n",
    "    # Select specified tile, with 2-cell padding for taking of derivatives\n",
    "    ix, iy = tile_index\n",
    "    p = p.isel(yp=slice(max(iy*tile_size-2,0), (iy+1)*tile_size+2),\n",
    "               xp=slice(max(ix*tile_size-2,0), (ix+1)*tile_size+2))\n",
    "    xp = p.xp.values # grab values of dask arrays\n",
    "    yp = p.yp.values\n",
    "    time = p.time.values\n",
    "    \n",
    "    p = p.data\n",
    "    print('p shape with buffer of 2 on either side = ',p.shape)\n",
    "    \n",
    "    # Concatenate two columns/rows on ends for correct handling of boundaries in derivatives\n",
    "    if ix==0:\n",
    "        p = da.concatenate([(2./gamma)*p[:,slice(0,1),:] + ((gamma-2)/gamma)*p[:,slice(1,2),:], p], axis=1)\n",
    "        p = da.concatenate([((4+alpha_bc+0.5*alpha_bc**2)/(gamma**2))*p[:,slice(1,2),:] - (4/(gamma**2))*p[:,slice(2,3),:] + ((gamma-alpha_bc)/gamma)*p[:,slice(3,4),:], p], axis=1)\n",
    "    if iy==0:\n",
    "        p = da.concatenate([(2./gamma)*p[slice(0,1),:,:] + ((gamma-2)/gamma)*p[slice(1,2),:,:], p], axis=0)\n",
    "        p = da.concatenate([((4+alpha_bc+0.5*alpha_bc**2)/(gamma**2))*p[slice(1,2),:,:] - (4/(gamma**2))*p[slice(2,3),:,:] + ((gamma-alpha_bc)/gamma)*p[slice(3,4),:,:], p], axis=0)\n",
    "    if ix==9:\n",
    "        p = da.concatenate([(2./gamma)*p[:,slice(-1,None),:] + ((gamma-2)/gamma)*p[:,slice(-2,-1),:], p], axis=1)\n",
    "        p = da.concatenate([((4+alpha_bc+0.5*alpha_bc**2)/(gamma**2))*p[:,slice(-2,-1),:] - (4/(gamma**2))*p[:,slice(-3,-2),:] + ((gamma-alpha_bc)/gamma)*p[:,slice(-4,-3),:], p], axis=1)\n",
    "    if iy==9:\n",
    "        p = da.concatenate([(2./gamma)*p[slice(-1,None),:,:] + ((gamma-2)/gamma)*p[slice(-2,-1),:,:], p], axis=0)\n",
    "        p = da.concatenate([((4+alpha_bc+0.5*alpha_bc**2)/(gamma**2))*p[slice(-2,-1),:,:] - (4/(gamma**2))*p[slice(-3,-2),:,:] + ((gamma-alpha_bc)/gamma)*p[slice(-4,-3),:,:], p], axis=0)\n",
    "    \n",
    "    # Update size variables\n",
    "    ny, nx, nt = p.shape\n",
    "    print('after adding two cells for boundaries ',p.shape)\n",
    "    p = p.rechunk(chunks={0: ny, 1: nx})\n",
    "        \n",
    "    def Jacobian(p):\n",
    "        # Jacobian stencil\n",
    "        p_cc = p\n",
    "        p_ac = np.roll(p_cc,  2, axis=0)\n",
    "        p_bc = np.roll(p_cc,  1, axis=0)\n",
    "        p_dc = np.roll(p_cc, -1, axis=0)\n",
    "        p_ec = np.roll(p_cc, -2, axis=0)\n",
    "    \n",
    "        p_ca = np.roll(p_cc, -2, axis=1)\n",
    "        p_cb = np.roll(p_cc, -1, axis=1)\n",
    "        p_cd = np.roll(p_cc,  1, axis=1)\n",
    "        p_ce = np.roll(p_cc,  2, axis=1)\n",
    "    \n",
    "        p_bb = np.roll(p_bc, -1, axis=1)\n",
    "        p_bd = np.roll(p_bc,  1, axis=1)\n",
    "        p_db = np.roll(p_dc, -1, axis=1)\n",
    "        p_dd = np.roll(p_dc,  1, axis=1) \n",
    "        \n",
    "        p_y = - p_cd + p_cb\n",
    "        p_x = - p_bc + p_dc\n",
    "        delp_y = - (p_ce + p_bd + p_dd - 4*p_cd) + (p_ca + p_bb + p_db - 4*p_cb)\n",
    "        delp_x = - (p_bb + p_ac + p_bd - 4*p_bc) + (p_db + p_ec + p_dd - 4*p_dc)\n",
    "    \n",
    "        J = delp_x*p_y - delp_y*p_x\n",
    "        \n",
    "        return J\n",
    "\n",
    "    # Evaluate the Jacobian function\n",
    "    J = p.map_blocks(Jacobian)\n",
    "    \n",
    "    # Trim off added cells\n",
    "    J = J[2:ny-2, 2:nx-2, :]\n",
    "    p = p[2:ny-2, 2:nx-2, :]\n",
    "    \n",
    "    # Mask boundaries, if desired (mask = number of cells to mask on each boundary)\n",
    "    if ix == 0 and mask:\n",
    "        J = J[:,slice(mask,None),:]\n",
    "        p = p[:,slice(mask,None),:]\n",
    "    if iy == 0 and mask:\n",
    "        J = J[slice(mask,None),:,:]\n",
    "        p = p[slice(mask,None),:,:]\n",
    "    if ix == 9 and mask:\n",
    "        J = J[:,slice(0,-mask),:]\n",
    "        p = p[:,slice(0,-mask),:]\n",
    "    if iy == 9 and mask:\n",
    "        J = J[slice(0,-mask),:,:]\n",
    "        p = p[slice(0,-mask),:,:]\n",
    "        \n",
    "    print('after masking 2 cells at boundary ',J.shape)\n",
    "\n",
    "    # Multiplicative factor due to derivative\n",
    "    J = (1./(4*(dx**4)))*J\n",
    "    \n",
    "    # Use smaller spatial chunks for fft\n",
    "    J = J.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    p = p.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    \n",
    "    print('p shape after chunking/10 = ',p.shape)\n",
    "        \n",
    "    # Function that detrends, windows, and takes fft\n",
    "    def fft_block(var):\n",
    "        var = detrend_func(var,'time')\n",
    "        var = window_func(var,'time')\n",
    "        varhat = (1./var.shape[2])*np.fft.rfft(var, axis=2)\n",
    "        return varhat\n",
    "    \n",
    "    # Execute fft function above\n",
    "    Jhat = J.map_blocks(fft_block)\n",
    "    phat = p.map_blocks(fft_block)\n",
    "    \n",
    "    Jhat = Jhat.rechunk(chunks={0: tile_size, 1:tile_size, 2: 365})\n",
    "    phat = phat.rechunk(chunks={0: tile_size, 1:tile_size, 2: 365})\n",
    "\n",
    "    # Multiply by constants\n",
    "    KE = -(H[z] / (f0**3 * Htot)) * ((phat.conj()*Jhat).real)\n",
    "    \n",
    "    print('final shape = ',KE.shape)\n",
    "\n",
    "    # Sum over x- and y-axes\n",
    "    KE = da.sum(KE, axis=(0,1))\n",
    "    \n",
    "    KE = KE.compute()\n",
    "    \n",
    "    # Wrap as DataArray\n",
    "    n = len(time)\n",
    "    d = time[1] - time[0]\n",
    "    freq = np.fft.rfftfreq(n, d)\n",
    "    \n",
    "    KE = xr.DataArray(KE, \n",
    "                      dims=['freq'], \n",
    "                      coords={'freq': freq,\n",
    "                              'xp': xp.mean(),\n",
    "                              'yp': yp.mean()})\n",
    "    \n",
    "    return KE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PE\n",
    "\n",
    "\n",
    "$$\n",
    "-\\frac{1}{f_0 H_{tot}} \\frac{1}{g_1'}  \\mathrm{Re}  \\left[ \\widehat{(p_2 - p_1)}^* \\widehat{J( p_1,p_2)} \\right]\n",
    "- \\frac{1}{f_0 H_{tot}} \\frac{1}{g_2'}  \\mathrm{Re}  \\left[ \\widehat{(p_3 - p_2)}^* \\widehat{J( p_2,p_3)} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calc_PE(dsx, tile_index, z=0):\n",
    "    \n",
    "    # Select variables\n",
    "    p1 = dsx.p.isel(z=z)\n",
    "    p2 = dsx.p.isel(z=z+1)\n",
    "    \n",
    "    # Work with DaskArrays\n",
    "    ix, iy = tile_index\n",
    "    p1 = p1.isel(yp=slice(max(iy*tile_size-1,0), (iy+1)*tile_size+1),\n",
    "                 xp=slice(max(ix*tile_size-1,0), (ix+1)*tile_size+1))\n",
    "    p2 = p2.isel(yp=slice(max(iy*tile_size-1,0), (iy+1)*tile_size+1),\n",
    "                 xp=slice(max(ix*tile_size-1,0), (ix+1)*tile_size+1))\n",
    "\n",
    "    xp = p1.xp.values\n",
    "    yp = p1.yp.values\n",
    "    time = p1.time.values\n",
    "    \n",
    "    p1 = p1.data\n",
    "    p2 = p2.data\n",
    "    \n",
    "    # Concatenate one column/row on ends for correct handling of boundaries in derivatives\n",
    "    if ix==0:\n",
    "        p1 = da.concatenate([(2./gamma)*p1[:,slice(0,1),:] + ((gamma-2)/gamma)*p1[:,slice(1,2),:], p1], axis=1)\n",
    "        p2 = da.concatenate([(2./gamma)*p2[:,slice(0,1),:] + ((gamma-2)/gamma)*p2[:,slice(1,2),:], p2], axis=1)\n",
    "    if iy==0:\n",
    "        p1 = da.concatenate([(2./gamma)*p1[slice(0,1),:,:] + ((gamma-2)/gamma)*p1[slice(1,2),:,:], p1], axis=0)\n",
    "        p2 = da.concatenate([(2./gamma)*p2[slice(0,1),:,:] + ((gamma-2)/gamma)*p2[slice(1,2),:,:], p2], axis=0)\n",
    "    if ix==9:\n",
    "        p1 = da.concatenate([(2./gamma)*p1[:,slice(-1,None),:] + ((gamma-2)/gamma)*p1[:,slice(-2,-1),:], p1], axis=1)\n",
    "        p2 = da.concatenate([(2./gamma)*p2[:,slice(-1,None),:] + ((gamma-2)/gamma)*p2[:,slice(-2,-1),:], p2], axis=1)\n",
    "    if iy==9:\n",
    "        p1 = da.concatenate([(2./gamma)*p1[slice(-1,None),:,:] + ((gamma-2)/gamma)*p1[slice(-2,-1),:,:], p1], axis=0)\n",
    "        p2 = da.concatenate([(2./gamma)*p2[slice(-1,None),:,:] + ((gamma-2)/gamma)*p2[slice(-2,-1),:,:], p2], axis=0)\n",
    "        \n",
    "    ny, nx, nt = p1.shape\n",
    "    p1 = p1.rechunk(chunks={0: ny, 1: nx})\n",
    "    p2 = p2.rechunk(chunks={0: ny, 1: nx})\n",
    "\n",
    "    # Take a single derivative\n",
    "    def Derivative(p, axis):\n",
    "        p_right = np.roll(p, 1, axis=axis)\n",
    "        p_left = np.roll(p, -1, axis=axis)\n",
    "        dp = p_left - p_right\n",
    "        return dp\n",
    "        \n",
    "    Derivative_x = lambda p: Derivative(p, 1)\n",
    "    Derivative_y = lambda p: Derivative(p, 0)\n",
    "    \n",
    "    # Evaluate the derivative function\n",
    "    p1x = p1.map_blocks(Derivative_x)\n",
    "    p1y = p1.map_blocks(Derivative_y)\n",
    "    p2x = p2.map_blocks(Derivative_x)\n",
    "    p2y = p2.map_blocks(Derivative_y)\n",
    "    \n",
    "    J = p1x*p2y - p1y*p2x\n",
    "    \n",
    "    # Multiplicative factor due to derivative\n",
    "    J = J/(4*(dx**2))\n",
    "    \n",
    "    pdiff = p2 - p1\n",
    "    \n",
    "    # Trim down to original tile size\n",
    "    J = J[1:ny-1, 1:nx-1, :]\n",
    "    pdiff = pdiff[1:ny-1, 1:nx-1, :]\n",
    "\n",
    "    # Mask boundaries, if desired (mask = number of cells to mask on each boundary)\n",
    "    if ix == 0 and mask:\n",
    "        J = J[:,slice(mask,None),:]\n",
    "        pdiff = pdiff[:,slice(mask,None),:]\n",
    "    if iy == 0 and mask:\n",
    "        J = J[slice(mask,None),:,:]\n",
    "        pdiff = pdiff[slice(mask,None),:,:]\n",
    "    if ix == 9 and mask:\n",
    "        J = J[:,slice(0,-mask),:] \n",
    "        pdiff = pdiff[:,slice(0,-mask),:]\n",
    "    if iy == 9 and mask:\n",
    "        J = J[slice(0,-mask),:,:]\n",
    "        pdiff = pdiff[slice(0,-mask),:,:]\n",
    "    \n",
    "    # Take fft (after detrend and window)\n",
    "    def fft_block(var): # var is numpy array\n",
    "        var = detrend_func(var,'time')\n",
    "        var = window_func(var,'time')\n",
    "        varhat = (1./var.shape[2])*np.fft.rfft(var, axis=2)\n",
    "        return varhat\n",
    "    \n",
    "    # Use smaller spatial chunks for fft\n",
    "    J = J.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    pdiff = pdiff.rechunk(chunks={0: tile_size/10, \n",
    "                                  1: tile_size/10, \n",
    "                                  2: nt})\n",
    "    \n",
    "    # Execute fft function above\n",
    "    Jhat = J.map_blocks(fft_block)\n",
    "    pdiffhat = pdiff.map_blocks(fft_block)\n",
    "    \n",
    "    #pdiffhat = da.fft.rfft(pdiff, axis=2)\n",
    "    Jhat = Jhat.rechunk( chunks={0: tile_size, 1:tile_size, 2: 365})\n",
    "    pdiffhat = pdiffhat.rechunk(chunks={0: tile_size, \n",
    "                                        1: tile_size, \n",
    "                                        2: 365})\n",
    "    # Multiply by constants\n",
    "    PE = -(1 / (f0 * Htot)*(1/g[0]))*(pdiffhat.conj()*Jhat).real\n",
    "\n",
    "    # Sum over x- and y-axes\n",
    "    PE = da.sum(PE, axis=(0,1))\n",
    "    \n",
    "    PE = PE.compute()\n",
    "    \n",
    "    # wrap as DataArray\n",
    "    n = len(time)\n",
    "    d = time[1] - time[0]\n",
    "    freq = np.fft.rfftfreq(n, d)\n",
    "    \n",
    "    PE = xr.DataArray(PE,\n",
    "                      dims=['freq'], \n",
    "                      coords={'freq': freq,\n",
    "                              'xp': xp.mean(),\n",
    "                              'yp': yp.mean()})\n",
    "    return PE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buoyancy\n",
    "\n",
    "$$\n",
    "-\\frac{1}{H_{tot}} \\mathrm{Re} \\left[ \\widehat{(p_2 - p_1)}^* \\widehat{e_1} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_buoyancy(dsx, tile_index):\n",
    "    # Select variables\n",
    "    p1 = dsx.p.isel(z=0)\n",
    "    p2 = dsx.p.isel(z=1)\n",
    "    e = dsx.e\n",
    "    \n",
    "    # Work with DaskArrays\n",
    "    ix, iy = tile_index\n",
    "    p1 = p1.isel(yp=slice(iy*tile_size, (iy+1)*tile_size),\n",
    "                 xp=slice(ix*tile_size, (ix+1)*tile_size))\n",
    "    p2 = p2.isel(yp=slice(iy*tile_size, (iy+1)*tile_size),\n",
    "                 xp=slice(ix*tile_size, (ix+1)*tile_size))\n",
    "    e = e.isel(yp=slice(iy*tile_size, (iy+1)*tile_size),\n",
    "                 xp=slice(ix*tile_size, (ix+1)*tile_size))\n",
    "    \n",
    "    xp = p1.xp.values\n",
    "    yp = p1.yp.values\n",
    "    time = p1.time.values\n",
    "    \n",
    "    p1 = p1.data\n",
    "    p2 = p2.data\n",
    "    e = e.data\n",
    "    \n",
    "    ny, nx, nt = p1.shape\n",
    "    \n",
    "    pdiff = p2 - p1\n",
    "    \n",
    "    # Mask boundaries, if desired (mask = number of cells to mask on each boundary)\n",
    "    if ix == 0 and mask:\n",
    "        e = e[:,slice(mask,None),:]\n",
    "        pdiff = pdiff[:,slice(mask,None),:]\n",
    "    if iy == 0 and mask:\n",
    "        e = e[slice(mask,None),:,:]\n",
    "        pdiff = pdiff[slice(mask,None),:,:]\n",
    "    if ix == 9 and mask:\n",
    "        e = e[:,slice(0,-mask),:]\n",
    "        pdiff = pdiff[:,slice(0,-mask),:]\n",
    "    if iy == 9 and mask:\n",
    "        e = e[slice(0,-mask),:,:]\n",
    "        pdiff = pdiff[slice(0,-mask),:,:]\n",
    " \n",
    "    # Take fft (after detrend and window)\n",
    "    def fft_block(var): # var is numpy array\n",
    "        var = detrend_func(var,'time')\n",
    "        var = window_func(var,'time')\n",
    "        varhat = (1.0/var.shape[2])*np.fft.rfft(var, axis=2)\n",
    "        return varhat\n",
    "    \n",
    "    # Resize for faster FFT\n",
    "    e = e.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    pdiff = pdiff.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "\n",
    "    # Execute fft function above\n",
    "    ehat = e.map_blocks(fft_block)\n",
    "    pdiffhat = pdiff.map_blocks(fft_block)\n",
    "    \n",
    "    # Resize back to original tile size (100)\n",
    "    e = e.rechunk(chunks={0: tile_size, \n",
    "                                  1: tile_size, \n",
    "                                  2: 365})\n",
    "    pdiff = pdiff.rechunk(chunks={0: tile_size, \n",
    "                                  1: tile_size, \n",
    "                                  2: 365})\n",
    "    \n",
    "    # Multiply by constants\n",
    "    buoyancy = -(1 / Htot)*(pdiffhat.conj()*ehat).real\n",
    "\n",
    "    # Sum over x- and y-axes\n",
    "    buoyancy = da.sum(buoyancy, axis=(0,1))\n",
    "    \n",
    "    buoyancy = buoyancy.compute()\n",
    "    \n",
    "    # wrap as DataArray\n",
    "    n = len(time)\n",
    "    d = time[1] - time[0]\n",
    "    freq = np.fft.rfftfreq(n, d)\n",
    "    \n",
    "    buoyancy = xr.DataArray(buoyancy,\n",
    "                      dims=['freq'], \n",
    "                      coords={'freq': freq,\n",
    "                              'xp': xp.mean(),\n",
    "                              'yp': yp.mean()})\n",
    "    \n",
    "    return buoyancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Windstress\n",
    "\n",
    "$$\n",
    "-\\frac{1}{H_{tot}} \\mathrm{Re} \\left[ \\widehat{p_1}^* \\widehat{w_{ek}} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_windstress(dsx, tile_index):\n",
    "    # Select variables\n",
    "    p = dsx.p.isel(z=0) # dimensions: (y,x,time) = (lat,lon,time)\n",
    "    taux = dsx.taux\n",
    "    tauy = dsx.tauy\n",
    "    \n",
    "    # Work with DaskArrays\n",
    "    #   - Cut 100 piece chunks, with padding on edges for derivatives\n",
    "    ix, iy = tile_index\n",
    "    p = p.isel(yp=slice(max(iy*tile_size,0), (iy+1)*tile_size),\n",
    "                 xp=slice(max(ix*tile_size,0), (ix+1)*tile_size))\n",
    "    taux = taux.isel(yp=slice(max(iy*tile_size-1,0), (iy+1)*tile_size+1),\n",
    "                 xp=slice(max(ix*tile_size-1,0), (ix+1)*tile_size+1))\n",
    "    tauy = tauy.isel(yp=slice(max(iy*tile_size-1,0), (iy+1)*tile_size+1),\n",
    "                 xp=slice(max(ix*tile_size-1,0), (ix+1)*tile_size+1))\n",
    "    \n",
    "    xp = p.xp.values\n",
    "    yp = p.yp.values\n",
    "    time = p.time.values\n",
    "    \n",
    "    # Put into numpy arrays (to access the data)\n",
    "    p = p.data\n",
    "    taux = taux.data \n",
    "    tauy = tauy.data\n",
    "    \n",
    "    # Concatenate rows/columns for boundary handling in derivative\n",
    "    if ix==0:\n",
    "        taux = da.concatenate([taux[:,slice(0,1),:], taux], axis=1)\n",
    "        tauy = da.concatenate([tauy[:,slice(0,1),:], tauy], axis=1)\n",
    "    if iy==0:\n",
    "        taux = da.concatenate([taux[slice(0,1),:,:], taux], axis=0)\n",
    "        tauy = da.concatenate([tauy[slice(0,1),:,:], tauy], axis=0)\n",
    "    if ix==9:\n",
    "        taux = da.concatenate([taux, taux[:,slice(-1,None),:]], axis=1)\n",
    "        tauy = da.concatenate([tauy, tauy[:,slice(-1,None),:]], axis=1)\n",
    "    if iy==9:\n",
    "        taux = da.concatenate([taux, taux[slice(-1,None),:,:]], axis=0)\n",
    "        tauy = da.concatenate([tauy, tauy[slice(-1,None),:,:]], axis=0)\n",
    "        \n",
    "    ny, nx, nt = taux.shape\n",
    "    taux = taux.rechunk(chunks={0: ny, 1: nx})\n",
    "    tauy = tauy.rechunk(chunks={0: ny, 1: nx})\n",
    "\n",
    "    def Derivative(tau, axis):\n",
    "        tau_right = np.roll(tau, 1, axis=axis)\n",
    "        tau_left = np.roll(tau, -1, axis=axis)\n",
    "        dtau = tau_left - tau_right\n",
    "        return dtau\n",
    "        \n",
    "    Derivative_x = lambda tau: Derivative(tau, 1)\n",
    "    Derivative_y = lambda tau: Derivative(tau, 0)\n",
    "    \n",
    "    # Run the derivative function\n",
    "    tauy_x = tauy.map_blocks(Derivative_x)\n",
    "    taux_y = taux.map_blocks(Derivative_y)\n",
    "\n",
    "    # Define Ekman velocity\n",
    "    wek = (1./f0) * (tauy_x - taux_y)\n",
    "    \n",
    "    # Trim matrix down to desired size after derivative\n",
    "    wek = wek[1:ny-1, 1:nx-1, :]\n",
    "    \n",
    "    # Construct ds: matrix of constants to divide by in taking of derivative\n",
    "    ds = da.ones(wek.shape, chunks=wek.chunks)*2*dx\n",
    "    if ix==0:\n",
    "        ds = da.concatenate( [ ds[:,slice(0,1),:]/2, ds[:,1:,:] ], axis = 1)\n",
    "    if iy==0:\n",
    "        ds = da.concatenate( [ ds[slice(0,1),:,:]/2, ds[1:,:,:] ], axis = 0)\n",
    "    if ix==9:\n",
    "        ds = da.concatenate( [ ds[:,slice(-1,None),:]/2, ds[:,:-1,:] ], axis = 1)\n",
    "    if iy==9:\n",
    "        ds = da.concatenate( [ ds[slice(-1, None),:,:]/2, ds[:-1,:,:] ], axis = 0)\n",
    "        \n",
    "    # Divide needed for derivatives\n",
    "    wek = wek / ds\n",
    "    \n",
    "    # Mask boundaries, if desired (mask = number of cells to mask on each boundary)\n",
    "    if ix == 0 and mask:\n",
    "        wek = wek[:,slice(mask,None),:]\n",
    "        p = p[:,slice(mask,None),:]\n",
    "    if iy == 0 and mask:\n",
    "        wek = wek[slice(mask,None),:,:]\n",
    "        p = p[slice(mask,None),:,:]\n",
    "    if ix == 9 and mask:\n",
    "        wek = wek[:,slice(0,-mask),:]\n",
    "        p = p[:,slice(0,-mask),:]\n",
    "    if iy == 9 and mask:\n",
    "        wek = wek[slice(0,-mask),:,:]\n",
    "        p = p[slice(0,-mask),:,:]\n",
    "    \n",
    "    # fft function\n",
    "    def fft_block(var): # var is numpy array\n",
    "        var = detrend_func(var,'time')\n",
    "        var = window_func(var,'time')\n",
    "        varhat = (1.0/var.shape[2])*np.fft.rfft(var, axis=2)\n",
    "        return varhat\n",
    "\n",
    "    # Rechunk arrays into even smaller chunks for fft calculation\n",
    "    wek = wek.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    p = p.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    \n",
    "    # Execute fft function above\n",
    "    wekhat = wek.map_blocks(fft_block)\n",
    "    phat = p.map_blocks(fft_block)\n",
    "    \n",
    "    wek = wek.rechunk(chunks={0: tile_size, \n",
    "                                  1: tile_size, \n",
    "                                  2: 365})\n",
    "    p = p.rechunk(chunks={0: tile_size, \n",
    "                                  1: tile_size, \n",
    "                                  2: 365})\n",
    "    \n",
    "    # Multiply together\n",
    "    windstress = -(1 / Htot)*(phat.conj()*wekhat).real\n",
    "\n",
    "    # Sum over x- and y-axes\n",
    "    windstress = da.sum(windstress, axis=(0,1))\n",
    "    \n",
    "    windstress = windstress.compute()\n",
    "    \n",
    "    # Wrap as DataArray\n",
    "    n = len(time)\n",
    "    d = time[1] - time[0]\n",
    "    freq = np.fft.rfftfreq(n, d)\n",
    "    \n",
    "    windstress = xr.DataArray(windstress,\n",
    "                      dims=['freq'], \n",
    "                      coords={'freq': freq,\n",
    "                              'xp': xp.mean(),\n",
    "                              'yp': yp.mean()})\n",
    "    \n",
    "    return windstress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom Drag\n",
    "\n",
    "$$\n",
    "\\frac{\\delta _{ek}}{2 f_0 H_{tot}} \\mathrm{Re} \\left[  \\widehat{p_3}^* \n",
    "\\widehat{\\nabla_H^2 p_3}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bottomDrag(dsx, tile_index):\n",
    "    \n",
    "    # Select variables\n",
    "    p = dsx.p.isel(z=2)\n",
    "        \n",
    "    ix, iy = tile_index\n",
    "    p = p.isel(yp=slice(max(iy*tile_size-1,0), (iy+1)*tile_size+1),\n",
    "               xp=slice(max(ix*tile_size-1,0), (ix+1)*tile_size+1))\n",
    "    xp = p.xp.values\n",
    "    yp = p.yp.values\n",
    "    time = p.time.values\n",
    "    \n",
    "    p = p.data\n",
    "    \n",
    "    # Concatenate one column/row on ends for correct handling of boundaries in derivatives\n",
    "    if ix==0:\n",
    "        p = da.concatenate([(2/gamma)*p[:,slice(0,1),:] + ((alpha_bc-gamma)/gamma)*p[:,slice(1,2),:], p], axis=1)\n",
    "    if iy==0:\n",
    "        p = da.concatenate([(2/gamma)*p[slice(0,1),:,:] + ((alpha_bc-gamma)/gamma)*p[slice(1,2),:,:], p], axis=0)\n",
    "    if ix==9:\n",
    "        p = da.concatenate([p, (2/gamma)*p[:,slice(-1,None),:] + ((alpha_bc-gamma)/gamma)*p[:,slice(-2,-1),:]], axis=1)\n",
    "    if iy==9:\n",
    "        p = da.concatenate([p, (2/gamma)*p[slice(-1,None),:,:] + ((alpha_bc-gamma)/gamma)*p[slice(-2,-1),:,:]], axis=0)\n",
    "        \n",
    "    ny, nx, nt = p.shape\n",
    "    p = p.rechunk(chunks={0: ny, 1: nx})\n",
    "        \n",
    "    # Function for calculating del**2 (Laplacian)\n",
    "    def del2(p):\n",
    "        # stencil\n",
    "        p_cc = p\n",
    "        p_bc = np.roll(p_cc,  1, axis=0)\n",
    "        p_dc = np.roll(p_cc, -1, axis=0)\n",
    "        p_cb = np.roll(p_cc, -1, axis=1)\n",
    "        p_cd = np.roll(p_cc,  1, axis=1)\n",
    "        \n",
    "        del2p = p_dc + p_cd + p_bc + p_cb - 4*p_cc\n",
    "\n",
    "        return del2p\n",
    "\n",
    "    # Run the del2 function\n",
    "    del2p = p.map_blocks(del2)\n",
    "\n",
    "    # Divide for derivative\n",
    "    del2p = (1./(dx**2))*del2p\n",
    "    \n",
    "    del2p = del2p[1:ny-1, 1:nx-1, :]\n",
    "    p = p[1:ny-1, 1:nx-1, :]\n",
    "    \n",
    "    # Mask boundaries, if desired (mask = number of cells to mask on each boundary)\n",
    "    if ix == 0 and mask:\n",
    "        del2p = del2p[:,slice(mask,None),:]\n",
    "        p = p[:,slice(mask,None),:]\n",
    "    if iy == 0 and mask:\n",
    "        del2p = del2p[slice(mask,None),:,:]\n",
    "        p = p[slice(mask,None),:,:]\n",
    "    if ix == 9 and mask:\n",
    "        del2p = del2p[:,slice(0,-mask),:] \n",
    "        p = p[:,slice(0,-mask),:]\n",
    "    if iy == 9 and mask:\n",
    "        del2p = del2p[slice(0,-mask),:,:]\n",
    "        p = p[slice(0,-mask),:,:]\n",
    "    \n",
    "    # fft function\n",
    "    def fft_block(var): # var is numpy array\n",
    "        var = detrend_func(var,'time')\n",
    "        var = window_func(var,'time')\n",
    "        varhat = (1./var.shape[2])*np.fft.rfft(var, axis=2)\n",
    "        return varhat\n",
    "    \n",
    "    # Rechunk for faster FFT\n",
    "    del2p = del2p.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    p = p.rechunk(chunks={0: tile_size/10, 1: tile_size/10, 2: nt})\n",
    "    \n",
    "    # Execute fft function above\n",
    "    del2phat = del2p.map_blocks(fft_block)\n",
    "    phat = p.map_blocks(fft_block)\n",
    "    \n",
    "    del2phat = del2phat.rechunk( chunks={0: tile_size, 1:tile_size, 2: 365})\n",
    "    phat = phat.rechunk(chunks={0: tile_size, 1:tile_size, 2: 365})\n",
    "\n",
    "    # Multiply all together\n",
    "    bottomDrag = (delta_ek / (2. * f0 * Htot)) *(phat.conj()*del2phat).real\n",
    "\n",
    "    # Sum over x- and y-axes\n",
    "    bottomDrag = da.sum(bottomDrag, axis=(0,1))\n",
    "    \n",
    "    bottomDrag = bottomDrag.compute()\n",
    "    \n",
    "    # wrap as DataArray\n",
    "    n = len(time)\n",
    "    d = time[1] - time[0]\n",
    "    freq = np.fft.rfftfreq(n, d)\n",
    "    \n",
    "    bottomDrag = xr.DataArray(bottomDrag, \n",
    "                      dims=['freq'], \n",
    "                      coords={'freq': freq,\n",
    "                              'xp': xp.mean(),\n",
    "                              'yp': yp.mean()})\n",
    "    \n",
    "    return bottomDrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 3.32 s, total: 1min 11s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from itertools import product\n",
    "\n",
    "# ceil(x/y) = (x+y+1)//y\n",
    "yi = range((961+tile_size+1)//(tile_size)) \n",
    "xi = range((961+tile_size+1)//(tile_size))\n",
    "\n",
    "tile_indexes = list(product(*[yi, xi]))\n",
    "\n",
    "KE1_sum = 0\n",
    "KE2_sum = 0\n",
    "KE3_sum = 0\n",
    "buoyancy_sum = 0\n",
    "PE1_sum = 0\n",
    "PE2_sum = 0\n",
    "windstress_sum = 0\n",
    "bottomDrag_sum = 0\n",
    "for tile_index in tile_indexes[:]:\n",
    "#     KE1 = calc_KE(dsx, tile_index, 0)\n",
    "#     KE2 = calc_KE(dsx, tile_index, 1)\n",
    "#     KE3 = calc_KE(dsx, tile_index, 2)\n",
    "#     KE1_sum += KE1\n",
    "#     KE2_sum += KE2\n",
    "#     KE3_sum += KE3\n",
    "    \n",
    "#     PE1 = calc_PE(dsx, tile_index, 0)\n",
    "#     PE2 = calc_PE(dsx, tile_index, 1)\n",
    "#     PE1_sum += PE1\n",
    "#     PE2_sum += PE2\n",
    "\n",
    "#     windstress = calc_windstress(dsx,tile_index)\n",
    "#     windstress_sum += windstress\n",
    "    \n",
    "#     buoyancy = calc_buoyancy(dsx, tile_index)\n",
    "#     buoyancy_sum += buoyancy\n",
    "    \n",
    "    bottomDrag = calc_bottomDrag(dsx,tile_index)\n",
    "    bottomDrag_sum += bottomDrag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
